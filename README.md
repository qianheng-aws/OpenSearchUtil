NOTE: This project is all generated by claude.

# OpenSearch Data Tools

一套用于 OpenSearch 数据导入和性能测试的 Python 工具集。

## 功能模块

### 1. Ingest 模块 - 数据导入
- **Parquet 导入**: 支持高效读取 Parquet 文件并批量导入 OpenSearch
- **CSV 导入**: 支持各种 CSV 格式，包括自定义分隔符、编码等

### 2. Benchmark 模块 - 性能测试
- **GraphLookup Benchmark**: 测试 OpenSearch PPL graphLookup 命令的性能
  - 支持不同 maxDepth 的梯度测试
  - 支持 uni/bi 方向测试
  - 自动计算中位数延迟

## 安装依赖

```bash
pip install -r requirements.txt
```

## 项目结构

```
OpenSearchIngestion/
├── ingest/                          # 数据导入模块
│   ├── __init__.py
│   ├── parquet_to_opensearch.py     # Parquet 导入
│   └── csv_to_opensearch.py         # CSV 导入
├── benchmark/                       # 性能测试模块
│   ├── __init__.py
│   └── graphlookup_benchmark.py     # GraphLookup 性能测试
├── example_usage.py                 # 使用示例
├── requirements.txt                 # 依赖列表
└── README.md                        # 文档
```

---

# Ingest 模块 - 数据导入

## 支持的文件格式

| 格式 | 文件扩展名 | 导入脚本 |
|------|-----------|---------|
| Parquet | `.parquet` | `ingest/parquet_to_opensearch.py` |
| CSV | `.csv`, `.tsv` | `ingest/csv_to_opensearch.py` |

## 快速开始

### 1. Parquet 文件导入

```bash
# 基本用法
python -m ingest.parquet_to_opensearch data.parquet my_index

# 带认证的远程 OpenSearch
python -m ingest.parquet_to_opensearch data.parquet my_index \
    --host your-opensearch-host.com \
    --port 443 \
    --username admin \
    --password your_password \
    --use-ssl
```

#### 程序化使用

```python
from ingest import ParquetToOpenSearchImporter

importer = ParquetToOpenSearchImporter(host='localhost', port=9200)
stats = importer.import_parquet_to_opensearch(
    parquet_file='data.parquet',
    index_name='my_index',
    doc_id_column='id'
)
print(f"成功导入 {stats['successful']} 条记录")
```

### 2. CSV 文件导入

```bash
# 基本用法
python -m ingest.csv_to_opensearch data.csv my_index

# 导入管道符分隔的文件
python -m ingest.csv_to_opensearch data.csv my_index --delimiter "|"

# 处理列名中的点号（OpenSearch 兼容）
python -m ingest.csv_to_opensearch data.csv my_index --delimiter "|" --replace-dots

# 自定义列名
python -m ingest.csv_to_opensearch data.csv my_index --delimiter "|" --column-names "col1,col2,col3"

# 完整选项
python -m ingest.csv_to_opensearch data.csv my_index \
    --delimiter "," \
    --encoding utf-8 \
    --parse-dates timestamp,created_at \
    --doc-id-column id
```

#### 程序化使用

```python
from ingest import CSVToOpenSearchImporter

importer = CSVToOpenSearchImporter(host='localhost', port=9200)
stats = importer.import_csv_to_opensearch(
    csv_file='data.csv',
    index_name='my_index',
    delimiter='|',
    replace_dots=True
)
print(f"成功导入 {stats['successful']} 条记录")
```

## Ingest 配置选项

### OpenSearch 连接配置

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `host` | str | localhost | OpenSearch 主机地址 |
| `port` | int | 9200 | OpenSearch 端口 |
| `username` | str | None | 认证用户名 |
| `password` | str | None | 认证密码 |
| `use_ssl` | bool | False | 是否使用 SSL |
| `verify_certs` | bool | False | 是否验证证书 |

### CSV 解析配置

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `delimiter` | str | `,` | 字段分隔符 |
| `encoding` | str | `utf-8` | 文件编码 |
| `replace_dots` | bool | False | 替换列名中的点号为下划线 |
| `column_names` | list | None | 自定义列名 |
| `parse_dates` | list | None | 需要解析为日期的列名 |

---

# Benchmark 模块 - 性能测试

## GraphLookup Benchmark

用于测试 OpenSearch PPL `graphLookup` 命令的性能。

### 测试流程

1. **随机选取起始点**: 从顶点索引中随机选取 N 个顶点作为 startValue
2. **梯度测试 maxDepth**: 对每个 startValue，测试不同的 maxDepth 值 (0, 1, 3, 5, ..., 50)
3. **方向测试**: 分别测试 `uni` (单向) 和 `bi` (双向) 遍历
4. **多次运行取中位数**: 每个配置运行 5 次，取中位数作为最终延迟值

### 快速开始

```bash
# 基本用法（使用默认配置）
python -m benchmark.graphlookup_benchmark

# 指定索引名称
python -m benchmark.graphlookup_benchmark \
    --vertex-index person \
    --edge-index connection

# 完整配置
python -m benchmark.graphlookup_benchmark \
    --host localhost \
    --port 9200 \
    --vertex-index person \
    --edge-index connection \
    --start-field id \
    --from-field target \
    --to-field source \
    --num-start-values 10 \
    --runs-per-test 5 \
    --max-depths "0,1,3,5,10,20,30,40,50" \
    --directions "uni,bi" \
    --output benchmark_report.json
```

### 命令行参数

#### OpenSearch 连接参数

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `--host` | localhost | OpenSearch 主机 |
| `--port` | 9200 | OpenSearch 端口 |
| `--username` | None | 认证用户名 |
| `--password` | None | 认证密码 |
| `--use-ssl` | False | 使用 SSL |
| `--verify-certs` | False | 验证证书 |

#### Benchmark 配置参数

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `--vertex-index` | person | 顶点索引名称 |
| `--edge-index` | connection | 边索引名称 |
| `--start-field` | id | 起始字段名 |
| `--from-field` | target | graphLookup fromField |
| `--to-field` | source | graphLookup toField |
| `--num-start-values` | 10 | 随机起始点数量 |
| `--runs-per-test` | 5 | 每个配置运行次数 |
| `--max-depths` | 0,1,3,5,...,50 | 测试的 maxDepth 值 |
| `--directions` | uni,bi | 测试的方向 |
| `--output` | None | JSON 报告输出文件 |
| `--quiet` | False | 静默模式 |

### 程序化使用

```python
from benchmark import GraphLookupBenchmark
from benchmark.graphlookup_benchmark import BenchmarkConfig

# 创建配置
config = BenchmarkConfig(
    host='localhost',
    port=9200,
    vertex_index='person',
    edge_index='connection',
    start_field='id',
    from_field='target',
    to_field='source',
    num_start_values=10,
    runs_per_test=5,
    max_depths=[0, 1, 3, 5, 10, 20, 30, 40, 50],
    directions=['uni', 'bi']
)

# 运行 benchmark
benchmark = GraphLookupBenchmark(config)
results = benchmark.run_benchmark()

# 打印摘要表格
benchmark.print_summary_table(results)

# 生成报告
report = benchmark.generate_report(results)
```

### 输出示例

```
================================================================================
BENCHMARK SUMMARY
================================================================================

--- Direction: uni ---
maxDepth   Avg Latency (ms)   Median (ms)     Min (ms)     Max (ms)     Avg Count
--------------------------------------------------------------------------------
0          12.34              11.50           8.20         18.90        100
1          25.67              24.30           19.50        35.20        250
3          58.90              55.40           45.30        78.60        800
5          112.45             108.20          95.60        145.30       1500
...

--- Direction: bi ---
maxDepth   Avg Latency (ms)   Median (ms)     Min (ms)     Max (ms)     Avg Count
--------------------------------------------------------------------------------
0          15.80              14.90           10.50        22.30        150
1          45.30              42.80           35.60        58.90        450
...
```

### JSON 报告格式

```json
{
  "timestamp": "2024-01-15T10:30:00",
  "config": {
    "vertex_index": "person",
    "edge_index": "connection",
    "num_start_values": 10,
    "runs_per_test": 5,
    "max_depths": [0, 1, 3, 5, 10, 20, 30, 40, 50],
    "directions": ["uni", "bi"]
  },
  "summary": {
    "uni": {
      "0": {"avg_latency_ms": 12.34, "median_latency_ms": 11.50, ...},
      "1": {...}
    },
    "bi": {...}
  },
  "details": [
    {
      "start_value": 12345,
      "max_depth": 0,
      "direction": "uni",
      "median_latency_ms": 10.5,
      "all_latencies_ms": [10.2, 10.5, 10.8, 11.0, 10.3],
      "result_count": 100
    },
    ...
  ]
}
```

---

# 故障排除

## 常见问题

### 1. 连接失败
```
ConnectionError: Unable to connect to OpenSearch
```
检查 OpenSearch 是否运行，端口是否正确。

### 2. CSV 列名包含点号
```
illegal_argument_exception: can't merge a non object mapping
```
使用 `--replace-dots` 参数替换列名中的点号。

### 3. PPL 查询超时
```
TimeoutError
```
增加 timeout 或减少 maxDepth 值。

### 4. 内存不足
```
MemoryError
```
减少 `chunk_size` 或使用 `nrows` 参数分批导入。

---

## 许可证

MIT License

---

## English Version

# OpenSearch Data Tools

A Python toolkit for OpenSearch data ingestion and performance benchmarking.

## Modules

### 1. Ingest Module
- Parquet file import
- CSV file import (with various parsing options)

### 2. Benchmark Module
- GraphLookup performance benchmark for PPL

## Quick Start

### Data Import

```bash
# Install dependencies
pip install -r requirements.txt

# Import Parquet
python -m ingest.parquet_to_opensearch data.parquet index_name

# Import CSV with pipe delimiter
python -m ingest.csv_to_opensearch data.csv index_name --delimiter "|" --replace-dots
```

### GraphLookup Benchmark

```bash
# Run benchmark with default settings
python -m benchmark.graphlookup_benchmark

# With custom configuration
python -m benchmark.graphlookup_benchmark \
    --vertex-index person \
    --edge-index connection \
    --max-depths "0,1,5,10,20,50" \
    --directions "uni,bi" \
    --output report.json
```

See source files for full documentation.
